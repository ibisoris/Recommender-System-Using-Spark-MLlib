{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f18eea6-8053-4c3b-af00-056e2c29b06d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Recommender System Using Spark MLlib on Steam Dataset\n",
    "\n",
    "**Name: Ibinabo Orifama**\n",
    "\n",
    "**StudentID: 00749582**\n",
    "\n",
    "### Introduction\n",
    "This task involves building a collaborative filtering recommender system with Apache Spark's MLlib on a dataset collected from Steam, an online video game distribution platform. The dataset comprises implicit feedback in the form of game purchases and playtime for various users, which is use to determine user preferences. We want to identify latent characteristics that represent people and games using the Alternating Least Squares (ALS) algorithm, which will allow us to make personalized game suggestions. The assignment entails using MLflow for \n",
    "\n",
    "- data preparation, \n",
    "- model training, \n",
    "- evaluating the model,\n",
    "- hyperparameter tuning,\n",
    "- recommendation, and \n",
    "- experiment tracking in the Databricks environment.\n",
    "\n",
    "In this task, several approaches were explored and experimented for training and evaluating the collaborative filtering recommender system, which including \n",
    "\n",
    "- using only play behavior \n",
    "- combining purchase and play behavior and \n",
    "- using purchase and play behavior with log scale playtimes to reduce the effect of outliers.\n",
    "\n",
    "The diiferent approaches were used to be able to identify the configuration that produce the best RMSE value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5255b796-b246-487c-997d-8ba1675dd3a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Import\n",
    "**Import mlflow**\n",
    "\n",
    "The first code snippet automates the tracking of Spark MLlib experiments using MLflow. By importing MLflow and activating ```mlflow.pyspark.ml.autolog()```, the system may automatically log model parameters, metrics, and artifacts during training, eliminating the need for manual logging. Setting the MLflow logger to ERROR also guarantees that only important messages are displayed, resulting in a cleaner and more focused output.\n",
    "\n",
    "**Loading the Dataset**\n",
    "\n",
    "The code sample ```df = spark.read.csv(\"/FileStore/tables/steam_200k.csv\", header=False, inferSchema=True)``` loads the Steam user interaction dataset into a Spark DataFrame and prepares it for analysis. It reads the CSV file without a header and automatically infers the data type of each column. The default column names (_c0 to _c3) are then replaced with more descriptive labels: **member_id** (unique user ID), **game** (game title), **behaviour** (either 'purchase' or 'play'), and **value** (1.0 for purchases or number of hours played). Finally, the first five rows are shown to ensure that the data was properly loaded and renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48934ce1-b8de-4b1c-a4c5-1a675a8bba38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Import mlflow and Autologs ML runs\n",
    "import mlflow\n",
    "import logging\n",
    "\n",
    "# Set the logging level for MLflow to ERROR to suppress info and warning messages in the output\n",
    "logging.getLogger('mlflow').setLevel(logging.ERROR)\n",
    "\n",
    "# Enable Spark MLlib autologging\n",
    "mlflow.pyspark.ml.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87df53b6-140a-42e8-9d3e-04c841655b6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+-----+\n|member_id|                game|behaviour|value|\n+---------+--------------------+---------+-----+\n|151603712|The Elder Scrolls...| purchase|  1.0|\n|151603712|The Elder Scrolls...|     play|273.0|\n|151603712|           Fallout 4| purchase|  1.0|\n|151603712|           Fallout 4|     play| 87.0|\n|151603712|               Spore| purchase|  1.0|\n|151603712|               Spore|     play| 14.9|\n|151603712|   Fallout New Vegas| purchase|  1.0|\n|151603712|   Fallout New Vegas|     play| 12.1|\n|151603712|       Left 4 Dead 2| purchase|  1.0|\n|151603712|       Left 4 Dead 2|     play|  8.9|\n+---------+--------------------+---------+-----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv(\"/FileStore/tables/steam_200k.csv\", header=False, inferSchema=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "df = df.withColumnRenamed(\"_c0\", \"member_id\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"game\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"behaviour\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"value\")\n",
    "\n",
    "# View the first few rows\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb75488-9afc-41c1-a6db-307b1cd02469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the Spark DataFrame output shown above, each row represent a user action in a single game. The rows are unique intereaction of purchase and hours played. The **member_id** column identifies the user, **game** provides the game's title, **behaviour** describes whether the user purchased or played the game, and **value** displays the numeric outcome of that behavior - 1.0 for a purchase and number of hours spent for a play action. This format collects implicit feedback that can be used to train a recommender system by examining trends in how users engage with various games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e2a070e-4618-43c3-b613-a025e3590fb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "The line ```df.printSchema()``` below displays the structure (schema) of the DataFrame. It displays the name of each column, as well as its data type and whether or not null values are allowed. In this dataset, the member_id: integer, game: string, behaviour: string, value: double. This helps in understand how Spark has interpreted the dataset. \n",
    "\n",
    "The line ```df.count()``` below returns the total number of rows or records in the DataFrame df. It does a full scan of the dataset to count all entries, which is beneficial for quickly determining the dataset size. In the context of the Steam dataset, this indicates how many user-game interactions (both purchases and play sessions) are captured in the data. The output of the count is 200000\n",
    "\n",
    "The line ```df.groupBy(\"behavior\").count().show()``` groups the DataFrame by behaviour column and counts the number of times each unique behavior appears. In this dataset, the typical behaviour values are 'purchase' and 'play'. This command helps to analyze the distribution of user actions by displaying the number of purchase and play events present.\n",
    "\n",
    "This line of code ```df.select(\"member_id\").distinct().count(), df.select(\"game\").distinct().count()```computes the total number of distinct users and unique games in the dataset by picking distinct values from the member_id and game columns. It contributes to determining the scale of the user-item interaction matrix, which is essential for developing a recommender system. Knowing how many users and games are involved allows you to analyze data sparsity, prepare for computational resources, and anticipate potential obstacles such as cold-start problems, which occur when new users or games have little interaction history.\n",
    "\n",
    "The line ```df.select([_sum(col(c).isNull().cast(\"int\")).alias(c + \"_nulls\") for c in df.columns]).show()``` checks for null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6db9754-f9d5-4003-a271-8c3c3b5f4c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- member_id: integer (nullable = true)\n |-- game: string (nullable = true)\n |-- behaviour: string (nullable = true)\n |-- value: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Check the schemas\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c027e6fd-1032-4cc3-92f2-458473023142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: 200000"
     ]
    }
   ],
   "source": [
    "# Count total records\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef9014b-c319-4180-b1d8-ec16ee0fec70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|behaviour| count|\n+---------+------+\n| purchase|129511|\n|     play| 70489|\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of behaviours\n",
    "df.groupBy(\"behaviour\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a4d13e-49aa-4432-9f69-1888d05808a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The output above displays the results indicating that there are 129,511 records of customers purchasing games and 70,489 records of users playing games. This indicates that the dataset contains more purchase actions than play actions. This knowledge is useful for understanding the data distribution and determining how to use it in a recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7741787f-bf74-41d3-8eb2-1aab3b06fc14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: (12393, 5155)"
     ]
    }
   ],
   "source": [
    "# Total number of users and games\n",
    "df.select(\"member_id\").distinct().count(), df.select(\"game\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf83a4c-26f3-4449-99cb-7d318147df42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "From the output above, the distinct users is 12393 and unique game is 5155 in the steam dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e56a85b-b65b-425b-90f0-18ad8eb293d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------------+-----------+\n|member_id_nulls|game_nulls|behaviour_nulls|value_nulls|\n+---------------+----------+---------------+-----------+\n|              0|         0|              0|          0|\n+---------------+----------+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum\n",
    "\n",
    "# Count nulls in each column\n",
    "df.select([_sum(col(c).isNull().cast(\"int\")).alias(c + \"_nulls\") for c in df.columns]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7200ba55-25d5-4b6c-a249-ee736c17668b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The result above shows that there are no null values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903acdc4-1b33-4e5a-81d4-4b415a9dd1d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Using Spark SQL for analysis**\n",
    "\n",
    "The line ```df.createOrReplaceTempView(\"steam\")``` registers the Spark DataFrame df as a temporary SQL view called \"steam\". This allows the running of SQL queries directly on the DataFrame with Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e1caa97-3b27-4937-a983-8f2e10db159b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating a temporary view for SQL queries\n",
    "df.createOrReplaceTempView(\"steam\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f442f6ef-efc2-40b4-b8c1-2309c780aadb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Visualization of the 10 most played games**\n",
    "\n",
    "The SQL query below extracts the top ten most played games in terms of total playtime from the temporary view steam. It filters the data to only include rows with the behaviour 'play' and then groups the remaining records by the game column. It sums the value column for each game to calculate the overall number of hours played. The results are arranged in descending order by total_playtime, with the highest cumulative play hours at the top. Using user activity, this query identifies the most engaging or popular games in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c1e05e-281a-4337-baba-74ad7f2367d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>game</th><th>total_playtime</th></tr></thead><tbody><tr><td>Dota 2</td><td>981684.5999999999</td></tr><tr><td>Counter-Strike Global Offensive</td><td>322771.6000000001</td></tr><tr><td>Team Fortress 2</td><td>173673.30000000005</td></tr><tr><td>Counter-Strike</td><td>134261.09999999998</td></tr><tr><td>Sid Meier's Civilization V</td><td>99821.30000000002</td></tr><tr><td>Counter-Strike Source</td><td>96075.50000000003</td></tr><tr><td>The Elder Scrolls V Skyrim</td><td>70889.3</td></tr><tr><td>Garry's Mod</td><td>49725.3</td></tr><tr><td>Call of Duty Modern Warfare 2 - Multiplayer</td><td>42009.899999999994</td></tr><tr><td>Left 4 Dead 2</td><td>33596.700000000004</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Dota 2",
         981684.5999999999
        ],
        [
         "Counter-Strike Global Offensive",
         322771.6000000001
        ],
        [
         "Team Fortress 2",
         173673.30000000005
        ],
        [
         "Counter-Strike",
         134261.09999999998
        ],
        [
         "Sid Meier's Civilization V",
         99821.30000000002
        ],
        [
         "Counter-Strike Source",
         96075.50000000003
        ],
        [
         "The Elder Scrolls V Skyrim",
         70889.3
        ],
        [
         "Garry's Mod",
         49725.3
        ],
        [
         "Call of Duty Modern Warfare 2 - Multiplayer",
         42009.899999999994
        ],
        [
         "Left 4 Dead 2",
         33596.700000000004
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "game",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_playtime",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT game, SUM(value) AS total_playtime  \nFROM steam\nWHERE behaviour = 'play'                   \nGROUP BY game                              \nORDER BY total_playtime DESC               \nLIMIT 10) SELECT `game`,SUM(`total_playtime`) `column_eb06cd9c38` FROM q GROUP BY `game`",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "game",
             "id": "column_eb06cd9c37"
            },
            "y": [
             {
              "column": "total_playtime",
              "id": "column_eb06cd9c38",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_eb06cd9c38": {
             "name": "total_playtime",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "a3d6cd1d-7994-4cbe-9c3a-629af23a18d2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.375,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "finished",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "game",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "game",
           "type": "column"
          },
          {
           "alias": "column_eb06cd9c38",
           "args": [
            {
             "column": "total_playtime",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Select the top 10 most played games based on total playtime\n",
    "SELECT game, SUM(value) AS total_playtime  \n",
    "FROM steam\n",
    "WHERE behaviour = 'play'                   -- Filter for rows where the user played the game\n",
    "GROUP BY game                              -- Group by game title\n",
    "ORDER BY total_playtime DESC               -- Sort games by total playtime in descending order\n",
    "LIMIT 10                                   -- Return only the top 10 games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "052c3ca9-9b95-4802-b35b-b78a46417714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "From the visualization, **Dota 2** has the most cumulative playtime, nearing about 1 million hours, indicating that it is by far the most engaging or popular game among users in this dataset. Other games with high playtime include **Counter-Strike: Global Offensive**, **Team Fortress 2**, and **Counter-Strike**, all of which have strong multiplayer communities. This information aids in the identification of games with the most devoted or active player bases and can be useful in proposing trending or highly engaging titles to new players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615010cd-db86-4870-86d1-51126b950cb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Visualization of 10 most purchased games**\n",
    "\n",
    "The SQL query below returns the top ten most purchased games by adding purchase counts (values) for each game with the behaviour 'purchase' and sorting the result in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67e5954-8757-4d25-9811-00691a2c0f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>game</th><th>total_Purchased</th></tr></thead><tbody><tr><td>Dota 2</td><td>4841.0</td></tr><tr><td>Team Fortress 2</td><td>2323.0</td></tr><tr><td>Unturned</td><td>1563.0</td></tr><tr><td>Counter-Strike Global Offensive</td><td>1412.0</td></tr><tr><td>Half-Life 2 Lost Coast</td><td>981.0</td></tr><tr><td>Counter-Strike Source</td><td>978.0</td></tr><tr><td>Left 4 Dead 2</td><td>951.0</td></tr><tr><td>Counter-Strike</td><td>856.0</td></tr><tr><td>Warframe</td><td>847.0</td></tr><tr><td>Half-Life 2 Deathmatch</td><td>823.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Dota 2",
         4841.0
        ],
        [
         "Team Fortress 2",
         2323.0
        ],
        [
         "Unturned",
         1563.0
        ],
        [
         "Counter-Strike Global Offensive",
         1412.0
        ],
        [
         "Half-Life 2 Lost Coast",
         981.0
        ],
        [
         "Counter-Strike Source",
         978.0
        ],
        [
         "Left 4 Dead 2",
         951.0
        ],
        [
         "Counter-Strike",
         856.0
        ],
        [
         "Warframe",
         847.0
        ],
        [
         "Half-Life 2 Deathmatch",
         823.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "game",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_Purchased",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT game, SUM(value) AS total_Purchased\nFROM steam\nWHERE behaviour = 'purchase'                    \nGROUP BY game                                   \nORDER BY total_purchased DESC                   \nLIMIT 10) SELECT `game`,SUM(`total_Purchased`) `column_520f30ab75` FROM q GROUP BY `game`",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "game",
             "id": "column_520f30ab74"
            },
            "y": [
             {
              "column": "total_Purchased",
              "id": "column_520f30ab75",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_520f30ab75": {
             "name": "total_Purchased",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "bc0543cd-ea15-4b49-9ad5-5405d745d875",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.2890625,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "finished",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "game",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "game",
           "type": "column"
          },
          {
           "alias": "column_520f30ab75",
           "args": [
            {
             "column": "total_Purchased",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Select the top 10 most purchased games based on total puchased\n",
    "SELECT game, SUM(value) AS total_Purchased\n",
    "FROM steam\n",
    "WHERE behaviour = 'purchase'                    -- Filter for rows where the user purchased the game\n",
    "GROUP BY game                                   -- Group by game title\n",
    "ORDER BY total_purchased DESC                   -- Sort games by total purchased in descending order\n",
    "LIMIT 10                                        -- Return only the top 10 games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20969761-fdf5-401f-8572-81cea2541766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The chart above displays the top ten most purchased games, with **Dota 2** leading by a significant margin, followed by **Team Fortress 2** and **Unturned**, showing the most popular titles based on purchase count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9abee5-a2bb-4a77-ae28-6b8adb60d8f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Checking for outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "198c8a46-a246-4044-afb8-e025a17c7c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n|summary|            value|\n+-------+-----------------+\n|  count|            70489|\n|   mean|48.87806324391008|\n| stddev| 229.335235996813|\n|    min|              0.1|\n|    max|          11754.0|\n+-------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "# Filter only play behavior\n",
    "play_df = df.filter(df.behaviour == 'play')\n",
    "\n",
    "# Describe playtime stats\n",
    "play_df.select(\"value\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f5df4af-c59f-469e-8971-8617cf401957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The playtime statistics above show a highly skewed distribution: the average playtime is approximately 48.88 hours, but the standard deviation is very high (229.34), and the maximum playtime is 11,754 hours. Because of the vast range, which includes many small values and a few extreme outliers, log transformation will be a highly successful strategy to use. Applying log1p() compresses these huge numbers, reduces skewness, and makes the data more suited for recommender system training.\n",
    "\n",
    "Before applying the log transform strategy, the data will be experimented first without the log to see the performance and RMSE values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "500b8893-ad79-469c-aae5-3b27a0c1237c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Preprocessing \n",
    "Data preprocessing is the process of converting raw data into a clean, structured, and useful format before passing it through a machine learning model or analytic pipeline. It guarantees that the data is consistent, full, and in the appropriate format for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9d9a050-d540-4b77-b3ad-5670ca2e0f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Case 1 - Using play behaviours only**\n",
    "\n",
    "The line of code below generates a new DataFrame named play_df and filters the original df to contain only rows with the behaviour 'play', indicating that the user has played the game. It then selects just three columns: member_id, game, and value. The value column, which displays the number of hours a user has spent playing the game, is renamed rating. This reformatted DataFrame is designed exclusively for training a collaborative filtering model (such as ALS). Play behaviour indicates true involvement because it tracks how long a user spent playing a game, whereas purchases do not always imply interest. Using play data allows the ALS model to learn user preferences more accurately, which leads to better recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96bb64f1-4bbe-4f78-b09c-a107e245ef16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "play_df = df.filter(df.behaviour == \"play\") \\\n",
    "               .select(\"member_id\", \"game\", \"value\") \\\n",
    "               .withColumnRenamed(\"value\", \"rating\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11008fe7-4e85-42a4-a8ec-fe499d1c8f2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Adding unique user_id and game_id**\n",
    "\n",
    "This code sample indexes the **member_id** and **game** columns using PySpark's StringIndexer and converts them into numerical columns **user_id** and **game_id**, which are required for training collaborative filtering models such as ALS. By default, these indexed columns are of DoubleType, thus the code employs the ```withColumn()``` function in conjunction with ```col()``` to explicitly cast both **user_id** and **game_id** to IntegerType for simpler and more exact data processing. Finally, it shows the first five rows of the modified DataFrame to ensure that the indexing and type conversion were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d207af53-9c28-47e0-8ff6-d7d188796244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------------+-------+------+\n|member_id|user_id|                game|game_id|rating|\n+---------+-------+--------------------+-------+------+\n|151603712|    585|The Elder Scrolls...|      6| 273.0|\n|151603712|    585|           Fallout 4|     64|  87.0|\n|151603712|    585|               Spore|    247|  14.9|\n|151603712|    585|   Fallout New Vegas|     23|  12.1|\n|151603712|    585|       Left 4 Dead 2|      4|   8.9|\n|151603712|    585|            HuniePop|    628|   8.5|\n|151603712|    585|       Path of Exile|     49|   8.1|\n|151603712|    585|         Poly Bridge|    914|   7.5|\n|151603712|    585|         Left 4 Dead|     36|   3.3|\n|151603712|    585|     Team Fortress 2|      1|   2.8|\n+---------+-------+--------------------+-------+------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Index users and games\n",
    "user_indexer = StringIndexer(inputCol=\"member_id\", outputCol=\"user_id\")\n",
    "game_indexer = StringIndexer(inputCol=\"game\", outputCol=\"game_id\")\n",
    "\n",
    "# Fit and transform\n",
    "play_df = user_indexer.fit(play_df).transform(play_df)\n",
    "play_df = game_indexer.fit(play_df).transform(play_df)\n",
    "\n",
    "#Convert datatype to integer\n",
    "play_df = play_df.withColumn(\"user_id\", col(\"user_id\").cast(\"int\")) \\\n",
    "                       .withColumn(\"game_id\", col(\"game_id\").cast(\"int\"))\n",
    "\n",
    "\n",
    "# Show transformed data\n",
    "play_df.select(\"member_id\", \"user_id\", \"game\", \"game_id\", \"rating\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d666f219-7330-4fe5-af1d-218244817c97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the result above, all interactions are associated with a single user (member_id = 151603712), who is assigned the indexed user_id = 585. Each row represents a game that the user has played, with the rating column showing the number of hours spent playing that game. This indexed and organized format is necessary for collaborative filtering because it enables the ALS algorithm to learn user preferences based on numeric user and item IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e767358a-0e3c-49de-ae22-69b65173f5b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Training - Case 1\n",
    "**Split the Dataset**:\n",
    "\n",
    "The line ```play_df.randomSplit([0.8, 0.2], seed=42)``` splits the play_df DataFrame into two subsets: training and testing datasets, using an 80/20 split. The ```randomSplit([0.8, 0.2], seed=42)``` technique ensures that 80% of the data is allocated randomly to the training set and 20% to the test set. The seed=42 option ensures reproducibility by utilizing a fixed random seed, which means the split will be the same every time the code is run. This stage is critical for evaluating machine learning models like ALS since it allows you to train the model on a subset of the data and then test its performance on unknown data.\n",
    "\n",
    "**ALS Algorithm**:\n",
    "\n",
    "The code below uses Alternating Least Squares (ALS) technique to train a recommendation model, which is ideal for collaborative filtering with implicit feedback. It instructs ALS to use the user_id, game_id, and rating columns, with rating indicating how many hours a user has spent playing a game. The model is configured to accept implicit preferences, remove rows with cold-start concerns, utilize non-negative factors, and run for 5 iterations with a regularization value of 0.01 and a latent factor rank of 10. The model is then trained on the training dataset with ```als.fit(training)```, which allows it to learn patterns in user-game interactions and generate suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334e81ae-d57b-44a2-a955-2d74f723c423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "(training, test) = play_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d90c66c-793a-4009-b008-0f5643febff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use the ALS Algorithm to train the model\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Initialize ALS\n",
    "als = ALS(\n",
    "    userCol=\"user_id\", itemCol=\"game_id\", ratingCol=\"rating\", implicitPrefs=True,\n",
    "    coldStartStrategy=\"drop\", nonnegative=True, maxIter=5, regParam=0.01, rank=10, seed=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063f10ba-bda9-427f-82ee-5b0cfdb1d6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "From the above output, a model is connected to one experiment. An experiment is a collection of runs. It serves as a folder that stores and arranges runs to train and test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e7e7c9-5bf1-4d47-8647-de47056ec00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Evaluating the Model\n",
    "**Make prediction**\n",
    "\n",
    "The ```.transform()``` method is used in the code below, to predict on the test dataset using the trained ALS model. The output is a new DataFrame called predictions, which retains the original columns from the test data (such as user_id, game_id, and rating), as well as an additional column called prediction, which has the model's estimated rating (i.e., expected playtime) for each user-game combination. The ```predictions.show()``` command shows the first few rows, allowing you to see how well the model predicts user preferences based on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7753310b-b9ef-4eb5-9869-67acb60a87dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+-------+-------+----------+\n|member_id|                game|rating|user_id|game_id|prediction|\n+---------+--------------------+------+-------+-------+----------+\n|  2083767|         CastleStorm|   0.7|    471|    823|0.26217592|\n|  2083767|Dungeon of the En...|  12.0|    471|    669|0.17652892|\n|  2083767|Might & Magic Her...|  17.2|    471|    342|0.20225078|\n|  2083767|       Time Clickers|   0.1|    471|    501|0.15152965|\n|  2083767|       Torchlight II|   1.5|    471|     38| 0.6109698|\n| 66650717|Age of Empires II...|  18.4|    148|     40|0.76415855|\n| 66650717|           Anno 2070|  75.0|    148|    259| 0.8601869|\n| 66650717|Battlestations Pa...|  94.0|    148|    994|0.18515491|\n| 66650717|Europa Universali...| 485.0|    148|    285|0.93188167|\n| 66650717|          Happy Wars|   3.7|    148|    261|0.06406071|\n+---------+--------------------+------+-------+-------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# make predictions using the transform() method\n",
    "predictions = model.transform(test)\n",
    "\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60bf38e3-e1e5-4e8b-9f35-5ba5cc9d8ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The displayed output above shows the outcomes of utilizing the trained ALS model to make predictions on test data. Each row represents a user-game interaction and contains the original values: user_id, game_id, and actual rating (number of hours played), as well as the newly created prediction column. The model internally uses the numeric indices user_id and game_id.\n",
    "The prediction column contains the model's estimated rating (i.e., expected playtime) for a particular user-game pair. For example, for **member_id** 2083767 or **user_id** 471 and the game **CastleStorm**, the actual rating is 0.7 hours played, but the model projected roughly 0.26 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5276115a-0f37-487d-a582-feb74a06a7ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Evaluating Accuracy  with RMSE**\n",
    "\n",
    "This code below assesses the trained ALS recommendation model's efficacy by computing the Root Mean Square Error (RMSE), which is the average difference between predicted and real playtime values in the test dataset. The prediction column (model output) and the rating column (actual values) are compared using PySpark's RegressionEvaluator. A lower RMSE shows that the model's predictions are closer to the actual values, implying better performance, whereas a higher RMSE suggests less accurate predictions. This stage is critical for assessing how effectively the model generalizes to previously unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd097da2-e083-4390-89ad-4c99c2f09c9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Play Behavior]- Root-mean-square error = 211.1568\nrmse = 211.157 \n"
     ]
    }
   ],
   "source": [
    "# Check the effectiveness of the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"[Play Behavior]- Root-mean-square error = {rmse:.4f}\")\n",
    "print('rmse = %g ' % (rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2103229c-430b-4d6f-8b7c-01e84f700085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The results show RMSE value is 211.1568, indicating that the predicted playtime values differ from the actual playtimes by around 211 hours. While this may appear to be a high number, it is crucial to realize that huge variances are prevalent in implicit feedback datasets such as Steam (where some users may play games for hundreds or thousands of hours), which might inflate the RMSE. This value provides a quantitative measure of model performance; however, in recommendation systems, the ranking quality is frequently more important than the projected rating. The next step is to combine both play and purchased behaviour to see if RMSE value will reduce or improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1f662c4-f2b7-43b6-85a5-29b5e8a39e75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Preprocessing \n",
    "**Case 2 - Using Purchase and Play Behaviour without log**\n",
    "\n",
    "Before combining purchase and play behaviour, it's crucial to note that each presents a unique but complimentary view of user preferences. Purchase behaviour reveals a user's interest or purpose, whereas play behaviour reflects actual engagement and enjoyment. By conbining both, building a more robust rating signal that captures both the decision to purchase a game and the degree to which it was enjoyed becomes possible. This method helps the model understand more complex patterns and increases the quality of personalized recommendations.\n",
    "\n",
    "The dataset is first prepared by assigning a constant rating (e.g., 5.0) to purchases and the actual playtime value to plays. These are all integrated into a single rating column. User and game identities are then indexed into numeric values using StringIndexer, and the resulting data is converted to integer types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90be3de2-9ba1-457b-981e-22c26bf0e696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Combine behaviors into a single 'rating' column\n",
    "full_df = df.withColumn(\n",
    "    \"rating\",\n",
    "    when(df.behaviour == \"purchase\", 1.0).otherwise(df.value)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9c3d213-613d-402a-a724-7df0141ab768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "#Convert 'member_id' column to a numeric index for ALS\n",
    "user_indexer = StringIndexer(inputCol=\"member_id\", outputCol=\"user_id\")\n",
    "\n",
    "#Convert 'game' names column to a numeric index for ALS\n",
    "game_indexer = StringIndexer(inputCol=\"game\", outputCol=\"game_id\")\n",
    "\n",
    "#Fit the user indexer and apply it to the full dataset\n",
    "indexed_df = user_indexer.fit(full_df).transform(full_df)\n",
    "\n",
    "#Fit the game indexer and apply it to the user-indexed data\n",
    "indexed_df = game_indexer.fit(indexed_df).transform(indexed_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb4d7a94-02a2-4c81-8c02-74c9b43311ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+------+\n|user_id|                game|game_id|rating|\n+-------+--------------------+-------+------+\n|    635|The Elder Scrolls...|      8|   1.0|\n|    635|The Elder Scrolls...|      8| 273.0|\n|    635|           Fallout 4|    100|   1.0|\n|    635|           Fallout 4|    100|  87.0|\n|    635|               Spore|    332|   1.0|\n|    635|               Spore|    332|  14.9|\n|    635|   Fallout New Vegas|     29|   1.0|\n|    635|   Fallout New Vegas|     29|  12.1|\n|    635|       Left 4 Dead 2|      4|   1.0|\n|    635|       Left 4 Dead 2|      4|   8.9|\n+-------+--------------------+-------+------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Convert user_id and game_id to integers\n",
    "combined_df = indexed_df.select(\"user_id\",\"game\", \"game_id\", \"rating\") \\\n",
    "                        .withColumn(\"user_id\", col(\"user_id\").cast(\"int\")) \\\n",
    "                        .withColumn(\"game_id\", col(\"game_id\").cast(\"int\"))\n",
    "\n",
    "#Display the first 10 rows with the original and indexed values\n",
    "combined_df.select(\"user_id\",\"game\", \"game_id\", \"rating\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d29c652-f714-4ba8-a1c0-4c1d964f7024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the table above, For example, user_id 635 purchased **The Elder Scrolls** (with a 1.0 rating) and played it for 273.0 hours. This trend is consistent across other games, such as **Fallout 4** (1.0 for purchase, 87.0 for play) and Spore (1.0 for purchase, 14.9 for play), indicating that each interaction type is logged independently, providing deeper information to the recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57bb3f87-c87e-4768-996e-c1fe22a31611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Training - Case 2\n",
    "The dataset is then split into training and testing sets, and an ALS model is trained using implicit feedback parameters. Finally, RMSE is used to assess how accurate the model predicts user preferences based on both behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08246a2c-a0e9-4d7b-a3b2-7881d8169f46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Split the combined_df dataset\n",
    "(training_combined, test_combined) = combined_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbab461a-870d-49ed-b652-2c80b3c6e87e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use the ALS Algorithm to train the model\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "#initialize ALS\n",
    "als_combined = ALS(userCol=\"user_id\", itemCol=\"game_id\", ratingCol=\"rating\", implicitPrefs=True, coldStartStrategy=\"drop\",nonnegative=True, maxIter=5, regParam=0.01, rank=10\n",
    ")\n",
    "\n",
    "#Train the combined model\n",
    "model_combined = als_combined.fit(training_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972c4279-63a1-4a96-8b6e-a8b561bad9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Evaluating Accuracy  with RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3101ed01-9f4d-492b-84fa-6e83dd4f3027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Combined Behavior] RMSE: 123.1619\n"
     ]
    }
   ],
   "source": [
    "# Import RegressionEvaluator for evaluating model accuracy\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Use the trained model to generate predictions on the test dataset\n",
    "predictions_combined = model_combined.transform(test_combined)\n",
    "\n",
    "# Initialize an RMSE evaluator to measure prediction error\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate and print the RMSE score for the combined behaviour model\n",
    "rmse_combined = evaluator.evaluate(predictions_combined)\n",
    "print(f\"[Combined Behavior] RMSE: {rmse_combined:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaf10014-583c-4a15-8be3-0dd6349e2440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explanation of Result**\n",
    "\n",
    "The combined behaviour model had a Root Mean Square Error (RMSE) of 123.2005, which was significantly better than the play-only model, which had an RMSE of around 211.1568. This suggests that combining purchase and play behaviours yields a little better result. The final case will be to apply log scale to the playtime behaviour to look for better improvement of the RMSE values before making recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ed658d6-19d0-43c6-a6aa-2f48ef03d2f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Preprocessing \n",
    "**CASE 3: Combine Purchase and Play with Log-Scaled Playtime**\n",
    "\n",
    "The first two cases above yielded relatively high RMSE values of 211.157 and 123.1619, respectively, when play-only behavior was used and combined purchase and play (without transformation). The significant RMSE, especially in the play-only model, shows that excessive playtime outliers may have affected model performance. To solve this, a third experiment was carried out that integrated purchase and play behavior but used log-scaling for playtime. As seen in the following section, this modification reduces the impact of large outliers and ensures more balanced input for training the recommendation model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6537f17a-cde8-446d-8fb7-8a3b26e94178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+-----+------------------+\n|member_id|                game|behaviour|value|            rating|\n+---------+--------------------+---------+-----+------------------+\n|151603712|The Elder Scrolls...| purchase|  1.0|               1.0|\n|151603712|The Elder Scrolls...|     play|273.0|5.6131281063880705|\n|151603712|           Fallout 4| purchase|  1.0|               1.0|\n|151603712|           Fallout 4|     play| 87.0| 4.477336814478207|\n|151603712|               Spore| purchase|  1.0|               1.0|\n|151603712|               Spore|     play| 14.9| 2.766319109226186|\n|151603712|   Fallout New Vegas| purchase|  1.0|               1.0|\n|151603712|   Fallout New Vegas|     play| 12.1|2.5726122302071057|\n|151603712|       Left 4 Dead 2| purchase|  1.0|               1.0|\n|151603712|       Left 4 Dead 2|     play|  8.9|2.2925347571405443|\n+---------+--------------------+---------+-----+------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import when, col, log1p\n",
    "\n",
    "# Create a rating column: 1.0 for purchases, log-scaled playtime otherwise\n",
    "combined_df_log = df.withColumn(\n",
    "    \"rating\",\n",
    "    when(col(\"behaviour\") == \"purchase\", 1.0)\n",
    "    .otherwise(log1p(col(\"value\")))\n",
    ")\n",
    "\n",
    "# Check a few rows to verify\n",
    "combined_df_log.select(\"member_id\", \"game\", \"behaviour\", \"value\", \"rating\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67977c06-dd42-4564-90c7-4d57005a6b13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+------------------+\n|user_id|                game|game_id|            rating|\n+-------+--------------------+-------+------------------+\n|    635|The Elder Scrolls...|      8|               1.0|\n|    635|The Elder Scrolls...|      8|5.6131281063880705|\n|    635|           Fallout 4|    100|               1.0|\n|    635|           Fallout 4|    100| 4.477336814478207|\n|    635|               Spore|    332|               1.0|\n|    635|               Spore|    332| 2.766319109226186|\n|    635|   Fallout New Vegas|     29|               1.0|\n|    635|   Fallout New Vegas|     29|2.5726122302071057|\n|    635|       Left 4 Dead 2|      4|               1.0|\n|    635|       Left 4 Dead 2|      4|2.2925347571405443|\n+-------+--------------------+-------+------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Index user and game columns\n",
    "user_indexer = StringIndexer(inputCol=\"member_id\", outputCol=\"user_id\")\n",
    "game_indexer = StringIndexer(inputCol=\"game\", outputCol=\"game_id\")\n",
    "indexed_log_df = user_indexer.fit(combined_df_log).transform(combined_df_log)\n",
    "indexed_log_df = game_indexer.fit(indexed_log_df).transform(indexed_log_df)\n",
    "\n",
    "# Cast user_id and game_id to int\n",
    "indexed_log_df = indexed_log_df.withColumn(\"user_id\", col(\"user_id\").cast(\"int\"))\n",
    "indexed_log_df = indexed_log_df.withColumn(\"game_id\", col(\"game_id\").cast(\"int\"))\n",
    "\n",
    "#Display the first 10 rows with the original and indexed values\n",
    "indexed_log_df.select(\"user_id\",\"game\", \"game_id\", \"rating\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "848ac35f-db31-4024-a72b-10d9eb036783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Training - Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27677074-4e64-4a57-9d5d-cdf82dbf481a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use the ALS Algorithm to train the model\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Split the data\n",
    "training_log, test_log = indexed_log_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train ALS model using log-scaled combined data\n",
    "als_log = ALS(\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"game_id\",\n",
    "    ratingCol=\"rating\",\n",
    "    implicitPrefs=True,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    "    maxIter=5,\n",
    "    rank=15,\n",
    "    regParam=0.001\n",
    ")\n",
    "\n",
    "model_log = als_log.fit(training_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d51cbd88-5266-4888-a606-d5a5d6fd404f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Evaluating Accuracy  with RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93cb8161-ae48-48db-9ebc-b4c44619ce8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Combined (Log-Scaled)] RMSE: 1.4618\n"
     ]
    }
   ],
   "source": [
    "# Import RegressionEvaluator for evaluating model accuracy\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions_log = model_log.transform(test_log)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse_log = evaluator.evaluate(predictions_log)\n",
    "print(f\"[Combined (Log-Scaled)] RMSE: {rmse_log:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3057c074-3111-4bac-abee-91389629f539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hyperparameter Tuning - Case 3\n",
    "Before using hyperparameter tuning, it is important to note that ALS performance can vary greatly based on the values of key parameters such as rank, regParam, and alpha. Hyperparameter tuning entails evaluating various combinations of these parameters to determine which arrangement produces the best accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d030db03-0743-426a-b2b8-d5264c675ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank=5, regParam=0.001] → RMSE: 1.5067\n[rank=5, regParam=0.01] → RMSE: 1.5084\n[rank=5, regParam=0.1] → RMSE: 1.5109\n[rank=10, regParam=0.001] → RMSE: 1.4815\n[rank=10, regParam=0.01] → RMSE: 1.4915\n[rank=10, regParam=0.1] → RMSE: 1.4955\n[rank=15, regParam=0.001] → RMSE: 1.4618\n[rank=15, regParam=0.01] → RMSE: 1.4738\n[rank=15, regParam=0.1] → RMSE: 1.4835\n\n-Best Log-Scaled Model Parameters-:\nRank: 15, RegParam: 0.001\nLowest RMSE: 1.4618\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# Hyperparameter Tuning with MLflow for Log-Scaled Model\n",
    "# -------------------------------------------------------\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# Define the grid of hyperparameters to try\n",
    "ranks = [5, 10, 15]                 # Number of latent features\n",
    "reg_params = [0.001, 0.01, 0.1]     # Regularization parameters\n",
    "\n",
    "# Initialize variables to track the best model\n",
    "best_rmse = float(\"inf\")           # Start with a very high RMSE\n",
    "best_params = {}                   # Store best-performing hyperparameters\n",
    "best_model = None                  # Store the best ALS model\n",
    "\n",
    "# Loop through each combination of rank and regParam\n",
    "for rank in ranks:\n",
    "    for reg in reg_params:\n",
    "        with mlflow.start_run():  # Start an MLflow run to log this experiment\n",
    "            # Initialize the ALS model with current hyperparameters\n",
    "            als = ALS(\n",
    "                userCol=\"user_id\",\n",
    "                itemCol=\"game_id\",\n",
    "                ratingCol=\"rating\",\n",
    "                implicitPrefs=True,          # Use implicit feedback (e.g., playtime)\n",
    "                coldStartStrategy=\"drop\",    # drop NaN predictions by dropping unseen data\n",
    "                nonnegative=True,            # Force non-negative latent factors\n",
    "                maxIter=5,                   # Number of ALS iterations\n",
    "                rank=rank,                   # Latent factors\n",
    "                regParam=reg                 # Regularization strength\n",
    "            )\n",
    "\n",
    "            # Train the ALS model using the training set\n",
    "            model = als.fit(training_log)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            predictions = model.transform(test_log)\n",
    "\n",
    "            # Evaluate the model using RMSE\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "            # Log parameters and metrics to MLflow\n",
    "            mlflow.log_param(\"rank\", rank)\n",
    "            mlflow.log_param(\"regParam\", reg)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.spark.log_model(model, \"ALSModel\")  # Log the trained model\n",
    "\n",
    "            # Print the result of this run\n",
    "            print(f\"[rank={rank}, regParam={reg}] → RMSE: {rmse:.4f}\")\n",
    "\n",
    "            # Update the best model if this one has lower RMSE\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_params = {\"rank\": rank, \"regParam\": reg}\n",
    "                best_model = model\n",
    "\n",
    "# Print the best hyperparameter combination and its RMSE\n",
    "print(\"\\n-Best Log-Scaled Model Parameters-:\")\n",
    "print(f\"Rank: {best_params['rank']}, RegParam: {best_params['regParam']}\")\n",
    "print(f\"Lowest RMSE: {best_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd6d5545-ed69-4b3d-be4a-7e8953211361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The results of a manual hyperparameter tuning experiment with MLflow for a log-scaled ALS (Alternating Least Squares) model shown above, explored various combinations of rank and regParam values to determine the best-performing model. The performance metric employed was the Root Mean Square Error (RMSE). Among all runs, the combination rank=15 and regParam=0.001 had the lowest RMSE of 1.4618, indicating that it is the most accurate model in the experiment. This findings validates the use of log-scaling for playtime data the best case, as the results will give higher prediction accuracy than previous cases.\n",
    "\n",
    "**Link for tracking experiment with MLflow**\n",
    "\n",
    "https://community.cloud.databricks.com/ml/experiments/3968102192852453?viewStateShareKey=f3d8b61be25cc02a484bd908ea2fa5af357aa57172239dee136c59c935bee414&compareRunsMode=TABLE&o=2812931347034770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "622b009a-f9e5-4f64-84ff-4a1de259034b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Generating Recommendation\n",
    "**10 Recommended Games for each user**\n",
    "\n",
    "The code below uses the trained ALS model to generate the top ten recommended games for each user by using ```recommendForAllUsers(10)```, which returns a DataFrame with each user_id and a list of game suggestions with projected ratings. The ```display(user_recs.head(5))``` line then shows the first five rows of this DataFrame, allowing you to evaluate how the model offers unique games for distinct users based on their prior activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db410ee1-8ba4-4846-b296-2471dff62a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>recommendations</th></tr></thead><tbody><tr><td>26</td><td>List(List(22, 1.3524247407913208), List(63, 1.345908761024475), List(65, 1.305184006690979), List(126, 1.260250449180603), List(112, 1.2478439807891846), List(91, 1.244828701019287), List(147, 1.219781756401062), List(148, 1.1794517040252686), List(93, 1.1759332418441772), List(15, 1.160675287246704))</td></tr><tr><td>27</td><td>List(List(63, 1.205193281173706), List(112, 1.194956660270691), List(91, 1.1916992664337158), List(65, 1.179060697555542), List(147, 1.1543536186218262), List(22, 1.122650384902954), List(130, 1.0895416736602783), List(1, 1.0458842515945435), List(177, 1.0452133417129517), List(126, 1.039563775062561))</td></tr><tr><td>28</td><td>List(List(91, 1.1761741638183594), List(63, 1.1394009590148926), List(112, 1.1025898456573486), List(7, 1.085028886795044), List(147, 1.0394741296768188), List(65, 1.0200464725494385), List(130, 1.0150917768478394), List(2, 0.971527636051178), List(18, 0.9546685218811035), List(0, 0.9489354491233826))</td></tr><tr><td>31</td><td>List(List(63, 1.3924576044082642), List(65, 1.3860780000686646), List(22, 1.3535970449447632), List(112, 1.3224185705184937), List(91, 1.3115018606185913), List(147, 1.2951369285583496), List(126, 1.2748198509216309), List(130, 1.2157305479049683), List(148, 1.202337622642517), List(32, 1.184873104095459))</td></tr><tr><td>34</td><td>List(List(22, 1.1418651342391968), List(63, 1.0850498676300049), List(126, 1.075913429260254), List(61, 1.0547938346862793), List(65, 1.0512057542800903), List(93, 1.0485742092132568), List(4, 1.0226904153823853), List(14, 1.0061743259429932), List(112, 1.0019207000732422), List(91, 0.9999445676803589))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         26,
         [
          [
           22,
           1.3524247407913208
          ],
          [
           63,
           1.345908761024475
          ],
          [
           65,
           1.305184006690979
          ],
          [
           126,
           1.260250449180603
          ],
          [
           112,
           1.2478439807891846
          ],
          [
           91,
           1.244828701019287
          ],
          [
           147,
           1.219781756401062
          ],
          [
           148,
           1.1794517040252686
          ],
          [
           93,
           1.1759332418441772
          ],
          [
           15,
           1.160675287246704
          ]
         ]
        ],
        [
         27,
         [
          [
           63,
           1.205193281173706
          ],
          [
           112,
           1.194956660270691
          ],
          [
           91,
           1.1916992664337158
          ],
          [
           65,
           1.179060697555542
          ],
          [
           147,
           1.1543536186218262
          ],
          [
           22,
           1.122650384902954
          ],
          [
           130,
           1.0895416736602783
          ],
          [
           1,
           1.0458842515945435
          ],
          [
           177,
           1.0452133417129517
          ],
          [
           126,
           1.039563775062561
          ]
         ]
        ],
        [
         28,
         [
          [
           91,
           1.1761741638183594
          ],
          [
           63,
           1.1394009590148926
          ],
          [
           112,
           1.1025898456573486
          ],
          [
           7,
           1.085028886795044
          ],
          [
           147,
           1.0394741296768188
          ],
          [
           65,
           1.0200464725494385
          ],
          [
           130,
           1.0150917768478394
          ],
          [
           2,
           0.971527636051178
          ],
          [
           18,
           0.9546685218811035
          ],
          [
           0,
           0.9489354491233826
          ]
         ]
        ],
        [
         31,
         [
          [
           63,
           1.3924576044082642
          ],
          [
           65,
           1.3860780000686646
          ],
          [
           22,
           1.3535970449447632
          ],
          [
           112,
           1.3224185705184937
          ],
          [
           91,
           1.3115018606185913
          ],
          [
           147,
           1.2951369285583496
          ],
          [
           126,
           1.2748198509216309
          ],
          [
           130,
           1.2157305479049683
          ],
          [
           148,
           1.202337622642517
          ],
          [
           32,
           1.184873104095459
          ]
         ]
        ],
        [
         34,
         [
          [
           22,
           1.1418651342391968
          ],
          [
           63,
           1.0850498676300049
          ],
          [
           126,
           1.075913429260254
          ],
          [
           61,
           1.0547938346862793
          ],
          [
           65,
           1.0512057542800903
          ],
          [
           93,
           1.0485742092132568
          ],
          [
           4,
           1.0226904153823853
          ],
          [
           14,
           1.0061743259429932
          ],
          [
           112,
           1.0019207000732422
          ],
          [
           91,
           0.9999445676803589
          ]
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recommendations",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"game_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"rating\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recommend top 10 games for each user\n",
    "user_recs = best_model.recommendForAllUsers(10)\n",
    "\n",
    "# Show first few recommendations\n",
    "display(user_recs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ce1c52-6b5b-4b21-bd89-350e426e8fc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the result above, each row corresponds to a distinct user_id and includes a recommendations column, which is an array of dictionaries. Each dictionary has a game_id and a rating, which indicate the model's prediction of how much the user would enjoy the game. For example, user 26 is more likely to prefer games with game_ids 22, 63, and 65, which have the highest expected ratings of 1.35, 1.34, and 1.31, respectively. These scores show the ALS model's confidence in how well each game matches the user's preferences based on previous user activity patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ecfa3b-21d0-4786-87e6-b2749b31ba9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explode Recommendation column and get game names**\n",
    "\n",
    "This code convert the nested recommendation structure to a readable format and uses StringIndexer to map game_id values back to game names. It pulls each recommended game per user, combines it with the original game titles, and shows the top 10 recommendations sorted by user and predicted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d6415d-b89c-4a1c-96c5-17ecc287f2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------------+-----------+\n|user_id|game                                             |score      |\n+-------+-------------------------------------------------+-----------+\n|12392  |Tomb Raider                                      |0.01252756 |\n|12392  |Metro 2033                                       |0.012381006|\n|12392  |Far Cry 3                                        |0.011811983|\n|12392  |BioShock Infinite                                |0.011759369|\n|12392  |Call of Duty Modern Warfare 2 - Multiplayer      |0.011639318|\n|12392  |The Witcher 2 Assassins of Kings Enhanced Edition|0.011567006|\n|12392  |Call of Duty Modern Warfare 2                    |0.011533891|\n|12392  |Grand Theft Auto IV                              |0.01138451 |\n|12392  |Saints Row The Third                             |0.011327478|\n|12392  |Hitman Absolution                                |0.011249619|\n|12391  |Tomb Raider                                      |0.038811088|\n|12391  |Far Cry 3                                        |0.036425974|\n|12391  |BioShock Infinite                                |0.03482058 |\n|12391  |Grand Theft Auto IV                              |0.034143902|\n|12391  |Hitman Absolution                                |0.033627946|\n|12391  |The Witcher 2 Assassins of Kings Enhanced Edition|0.032347355|\n|12391  |Saints Row The Third                             |0.03198194 |\n|12391  |Metro 2033                                       |0.03125161 |\n|12391  |The Elder Scrolls V Skyrim                       |0.030425342|\n|12391  |Batman Arkham Origins                            |0.029875226|\n+-------+-------------------------------------------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Flatten the recommendation structure\n",
    "exploded = user_recs.withColumn(\"rec\", explode(\"recommendations\"))\n",
    "flat_recs = exploded.select(\"user_id\", col(\"rec.game_id\").alias(\"game_id\"), col(\"rec.rating\").alias(\"score\"))\n",
    "\n",
    "# Generate mapping from game and game_id (manually indexed if not in df)\n",
    "game_indexer = StringIndexer(inputCol=\"game\", outputCol=\"game_id\")\n",
    "game_mapping_df = game_indexer.fit(df).transform(df).select(\"game\", \"game_id\").distinct()\n",
    "\n",
    "# Map game_id back to game names\n",
    "final_recs = flat_recs.join(game_mapping_df, on=\"game_id\", how=\"left\")\n",
    "\n",
    "# Show final recommendations for top users\n",
    "top_recs = final_recs.select(\"user_id\", \"game\", \"score\").orderBy(\"user_id\", \"score\", ascending=False)\n",
    "top_recs.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80a52715-abe1-41a9-b443-5fd041de1ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The result shows the top game recommendations for users. For example, user 12392 has been recommended games such as Tomb Raider, Metro 2033, and Far Cry 3, with predicted scores showing how much the ALS model thinks each user will enjoy them. Similarly, user 12391 has the same top recommendations, but with slightly better expected scores, such as 0.0388 for Tomb Raider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257a1837-1a7e-4cea-ac2f-409e1ed6bb06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Recommendation for a specific user**\n",
    "\n",
    "The code below provides game recommendations for a given user by first specifying a user_id (in this case, 0) and then building a single-row DataFrame with that ID. Using the trained ALS model, it uses recommendForUserSubset() to provide the top ten recommended games for that user based on projected preference ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55c37a87-0920-4f3a-b693-400f533c2e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>recommendations</th></tr></thead><tbody><tr><td>0</td><td>List(List(189, 3.70271897315979), List(260, 3.3830714225769043), List(265, 3.214069366455078), List(262, 3.2048869132995605), List(618, 2.02824068069458), List(61, 1.8862369060516357), List(555, 1.776806354522705), List(433, 1.7331064939498901), List(416, 1.7172329425811768), List(305, 1.6415585279464722))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         [
          [
           189,
           3.70271897315979
          ],
          [
           260,
           3.3830714225769043
          ],
          [
           265,
           3.214069366455078
          ],
          [
           262,
           3.2048869132995605
          ],
          [
           618,
           2.02824068069458
          ],
          [
           61,
           1.8862369060516357
          ],
          [
           555,
           1.776806354522705
          ],
          [
           433,
           1.7331064939498901
          ],
          [
           416,
           1.7172329425811768
          ],
          [
           305,
           1.6415585279464722
          ]
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recommendations",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"game_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"rating\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate Recommendations for a Specific User\n",
    "\n",
    "# Specify a user_id \n",
    "specific_user_id = 0 \n",
    "#create a dataframe\n",
    "single_user_df = spark.createDataFrame([(specific_user_id,)], [\"user_id\"])\n",
    "#Recommend for single user\n",
    "user_top_recs = best_model.recommendForUserSubset(single_user_df, 10)\n",
    "#Display first few result\n",
    "display(user_top_recs.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a32a83a8-5f70-454f-b9b9-0dda7ade3246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The ALS model predicts that user 0 will most likely enjoy game 189, which has the highest predicted rating of 3.70, followed by game 260 with a score of 3.38 and game 265 with 3.21. This format displays the top recommended games for a user before converting the IDs to game names for the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00c4744-1187-4df5-90bf-63bc175a58a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explode recommendation column to get game names**\n",
    "\n",
    "This code uses explode to convert the nested array of recommended games, resulting in each game appearing in its own row. It then takes the game_id and expected score (rating) for each recommendation and combines them with game_mapping_df to map game_ids back to their original game names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6831a0-673b-4539-878d-baa4a2c67841",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------+---------+\n|user_id|game                        |score    |\n+-------+----------------------------+---------+\n|0      |Football Manager 2013       |3.702719 |\n|0      |Football Manager 2012       |3.3830714|\n|0      |Football Manager 2015       |3.2140694|\n|0      |Football Manager 2014       |3.204887 |\n|0      |Football Manager 2011       |2.0282407|\n|0      |Age of Empires II HD Edition|1.8862369|\n|0      |Football Manager 2010       |1.7768064|\n|0      |Football Manager 2009       |1.7331065|\n|0      |Anomaly Warzone Earth       |1.717233 |\n|0      |Enclave                     |1.6415585|\n+-------+----------------------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Flatten and map game titles\n",
    "single_exploded = user_top_recs.withColumn(\"rec\", explode(\"recommendations\"))\n",
    "single_flat = single_exploded.select(\"user_id\", col(\"rec.game_id\").alias(\"game_id\"), col(\"rec.rating\").alias(\"score\"))\n",
    "single_final = single_flat.join(game_mapping_df, on=\"game_id\", how=\"left\")\n",
    "\n",
    "# Show top 10 recommended games for the user\n",
    "single_final.select(\"user_id\", \"game\", \"score\").orderBy(\"score\", ascending=False).show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c340f685-de41-493b-b341-271c36c37a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This result shows the top ten recommended games for user_id 0, arranged by predicted preference score. Games with the highest predicted scores, such as Football Manager 2013  and Football Manager 2012, indicate that the user is most likely to enjoy them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7496d741-6dae-4d8b-95d0-47827d036619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Conclusion\n",
    "The project successfully developed a collaborative filtering recommender system using the ALS algorithm on Steam user data, which included both play and purchase behaviour. Initial studies with play-only and combined raw data produced relatively high RMSE values, indicating the presence of outliers, particularly those resulting from long play durations. To remedy this, a third experiment was conducted in which playtime was log-transformed, yielding a more normalized rating distribution. This method considerably improved model performance and decreased RMSE, suggesting that log-scaling is a useful tool for dealing with skewed implicit feedback. Hyperparameter tuning and MLflow tracking helped in determining the best model design. Overall, the log-scaled combined behavior approach provided the most accurate and balanced recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40aedf3a-5c6a-4e0d-8abf-b87b73fba038",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reference\n",
    "\n",
    "1. https://docs.databricks.com/aws/en\n",
    "\n",
    "2. **_Lecture materials - Big Data Tools and Techniques_**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3968102192852460,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "IbinaboOrifama_BDTT_Task2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}